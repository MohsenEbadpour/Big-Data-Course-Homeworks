{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM4d4MeISR76AybHQoGxNBT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Big Data Course | Spring 2023\n","## First Homework \n","### Problem 01 - MapReduce for counting TV channels exchanges\n","#### Mohsen Ebadpour | M.Ebadpour@aut.ac.ir | 400131080\n","\n","---\n","\n"],"metadata":{"id":"m6zAAinf9dtM"}},{"cell_type":"markdown","source":["**Connecting to google drive to get dataset**"],"metadata":{"id":"gbrB2mQX-c1g"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2MJuroO_aZVn","executionInfo":{"status":"ok","timestamp":1681387322639,"user_tz":-210,"elapsed":2374,"user":{"displayName":"Mohsen Ebadpoor","userId":"04576676198792817882"}},"outputId":"bcc88309-bc23-403e-c27c-7db2699bf491"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","FileName = '/content/drive/MyDrive/data.txt'"]},{"cell_type":"markdown","source":["**Installing Libraries**"],"metadata":{"id":"bX9HwxDo-oB0"}},{"cell_type":"code","source":["! pip install pyspark\n","! pip install findspark\n","import findspark\n","findspark.init()\n","import pyspark\n","from pyspark.sql import *\n","from pyspark import SparkContext, SparkConf\n","\n","sc = SparkContext(appName='CountExchanges')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"xW6ebkpbbjK7","executionInfo":{"status":"error","timestamp":1681395522245,"user_tz":-210,"elapsed":12469,"user":{"displayName":"Mohsen Ebadpoor","userId":"04576676198792817882"}},"outputId":"5953a1ac-452b-44f9-c58e-69674d329ad2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyspark in /usr/local/lib/python3.9/dist-packages (3.3.2)\n","Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.9/dist-packages (from pyspark) (0.10.9.5)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: findspark in /usr/local/lib/python3.9/dist-packages (2.0.1)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-98-f843d59c17c2>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CountExchanges'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[1;32m    193\u001b[0m             )\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             self._do_init(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                     \u001b[0;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    431\u001b[0m                         \u001b[0;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                         \u001b[0;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=Spark, master=local[*]) created by __init__ at <ipython-input-4-cace8b582c3a>:8 "]}]},{"cell_type":"markdown","source":["**Increase recursive limits**"],"metadata":{"id":"iyRkq1cV-4Vt"}},{"cell_type":"code","source":["import sys\n","sys.setrecursionlimit(10000)"],"metadata":{"id":"PRxhmo0hrESZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Define Map and Reduce Functions**"],"metadata":{"id":"yP9PWVOY_FBa"}},{"cell_type":"code","source":["def MapChannels(item):\n","    tvs = list(item.split())\n","    source = tvs[0]\n","    del tvs[0]\n","    results = []\n","    for tv in tvs :\n","        results.append((tv,1))\n","    return results\n","\n","def CountExchane(value_1,value_2):\n","    return value_1 + value_2\n","\n","in_file = sc.textFile(FileName)\n","pairs = in_file.flatMap(MapChannels)\n","result = pairs.reduceByKey(CountExchane).collect()"],"metadata":{"id":"fWvciZSRcywm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Define Additional Functions to extract results**"],"metadata":{"id":"0C718a4Q_LQ6"}},{"cell_type":"code","source":["def print_items(item):\n","    print(\"Channel with ID #{a:4d} has {b:4d} exchanges\".format(a=int(item[0]),b=item[1]))\n","    \n","\n","def sort_key(item):\n","    if item[0] == \"3469\" or item[0] == \"5633\" or item[0] == \"1748\":\n","        print_items(item)  \n","    return -item[1]\n"],"metadata":{"id":"LtZnXFGqett4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Obtain Results**"],"metadata":{"id":"LRpZI51f_YP6"}},{"cell_type":"code","source":["print(\"-> Asked TV Channels:\")\n","result.sort(key=sort_key)\n","print()\n","\n","print(\"=> Top five TV Channels:\")\n","I = 1 \n","for item in result[:5]:\n","    print(I,end=\". \")\n","    I+=1\n","    print_items(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rN6O2SaN7e2o","executionInfo":{"status":"ok","timestamp":1681395124274,"user_tz":-210,"elapsed":371,"user":{"displayName":"Mohsen Ebadpoor","userId":"04576676198792817882"}},"outputId":"4a6bc681-c997-4205-f609-27674f673db6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-> Asked TV Channels:\n","Channel with ID #1748 has  130 exchanges\n","Channel with ID #3469 has  119 exchanges\n","Channel with ID #5633 has   30 exchanges\n","\n","=> Top five TV Channels:\n","1. Channel with ID # 859 has 1933 exchanges\n","2. Channel with ID #5306 has 1741 exchanges\n","3. Channel with ID #2664 has 1528 exchanges\n","4. Channel with ID #5716 has 1426 exchanges\n","5. Channel with ID #6306 has 1394 exchanges\n"]}]},{"cell_type":"markdown","source":["**Check results manually**"],"metadata":{"id":"7uzM7IEo_d7K"}},{"cell_type":"code","source":["file = open(FileName,\"r\")\n","lines = file.read().strip().split(\"\\n\")\n","res_check = {}\n","for line in lines:\n","    tvs = line.split()\n","    src = tvs[0]\n","    if src in res_check:\n","        res_check[src] += len(tvs) -1\n","    else:\n","        res_check[src] = len(tvs) -1\n","\n","counts = res_check.values()\n","res_check = list(zip(res_check.keys(),res_check.values()))\n","\n","\n","print(\"-> Asked TV Channels:\")\n","res_check.sort(key=sort_key)\n","print()\n","\n","print(\"=> Top five TV Channels:\")\n","I = 1 \n","for item in res_check[:5]:\n","    print(I,end=\". \")\n","    I+=1\n","    print_items(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KATTRgPuESc","executionInfo":{"status":"ok","timestamp":1681395831472,"user_tz":-210,"elapsed":769,"user":{"displayName":"Mohsen Ebadpoor","userId":"04576676198792817882"}},"outputId":"10e44e69-76db-4ced-f997-486e138a095b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-> Asked TV Channels:\n","Channel with ID #3469 has  119 exchanges\n","Channel with ID #1748 has  130 exchanges\n","Channel with ID #5633 has   30 exchanges\n","\n","=> Top five TV Channels:\n","1. Channel with ID # 859 has 1933 exchanges\n","2. Channel with ID #5306 has 1741 exchanges\n","3. Channel with ID #2664 has 1528 exchanges\n","4. Channel with ID #5716 has 1426 exchanges\n","5. Channel with ID #6306 has 1394 exchanges\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"05u6cq0t_6zQ"},"execution_count":null,"outputs":[]}]}